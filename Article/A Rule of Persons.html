<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>论文笔记 — A Rule of Persons, Not Machines</title>
  <style>
    body { font-family: "Helvetica Neue", Arial, "PingFang SC", "Microsoft YaHei", sans-serif; line-height: 1.8; background: #fafafa; color: #111; max-width: 900px; margin: 40px auto; padding: 24px; }
    header { background: white; padding: 20px 28px; border-radius: 12px; box-shadow: 0 6px 14px rgba(0,0,0,0.05); margin-bottom: 24px; }
    h1 { font-size: 26px; margin: 0 0 8px 0; }
    p { margin: 12px 0; }
    section { background: white; padding: 20px 28px; border-radius: 12px; box-shadow: 0 4px 10px rgba(0,0,0,0.04); margin-bottom: 20px; }
    footer { font-size: 13px; color: #555; text-align: center; margin-top: 32px; }
  </style>
</head>
<body>
  <header>
    <h1>论文笔记 — <em>A Rule of Persons, Not Machines: The Limits of Legal Automation</em></h1>
  </header>

  <section>
    <p>引用：Frank Pasquale, A Rule of Persons, Not Machines: The Limits of Legal Automation, 87 George Washington Law Review 1 (2019).</p>
    <h2>大纲</h2>
    
    <h2>摘要</h2>
    <p>对于许多法律未来主义者而言，律师的工作是自动化的主要目标。他们认为，大多数商业领域的法律实务具有算法属性：通过应用既定规则（即法律），数据（如事实）可被转化为输出结果（如协议或诉讼立场）。这些技术热衷者主张用计算机代码替代目前由人类撰写的合同与事实描述，并以法律自动化领域早期的成功案例作为概念验证。例如，税务软件TurboTax已帮助数百万美国人完成报税，算法也已接管股票交易中的某些环节。在法律规定与事实情况均清晰明确的实务领域，企业推动“法律规则形式化”的尝试或许能带来新的效率提升。</p>
    <p>然而，法律自动化也可能省略或排除重要的人类价值、必要的应变调整，以及无法简化的审慎治理。正当法律程序依赖于人与人之间的、为人设计的可理解的叙事性沟通，这类沟通无法被简化为软件代码。（正当程序的基础是人与人之间的沟通，并且这种沟通对双方来说都是可理解的。这种设计是以人为对话主体的。——机器/算法介入后，就会产生不匹配的问题。）语言正是法律这些核心层面的构成基础。为维护问责性与人道的法律秩序，相关的理由必须由负有责任的人以语言形式明确表达。这一关于合法性的基本要求，在多个场景中对法律自动化构成了限制，包括企业合规、产权登记与合同订立。一个健全且符合伦理的法律职业，会将法律语言的灵活性与精妙性视为实现公正、负责的社会秩序的前提，进而确保治理的核心是“人类的治理”（rule of persons），而非“机器的治理”（rule of machines）。</p>
   
    <h2>主要内容</h2>
    <h3>介绍</h3>
    <p>【法律自动化的趋势】</p>
    <p>法律会成为计算机科学的一个分支吗？考虑到律师作为社会秩序构建者与维护者所承担的独特职业角色，这一想法目前看似不切实际。然而，纵观各职业的发展史，其本质上充斥着“管辖权领域之争”——竞争的精英群体纷纷主张自己拥有解决特定问题或承担特定社会角色的权利。近年来，自动化向白领工作领域的渗透，促使未来主义者预测：人工智能或将完成如今许多由律师承担的任务，甚至完全取代律师。</p>
    <p>在法律实务的某些领域，作为人工智能基础构成的算法，已然取代了法律从业者的工作。例如，自动化的文档审查如今已成为“证据开示”（discovery）环节的常规操作；此外，人们在为美国国税局（IRS）准备年度纳税申报时，使用税务软件TurboTax的可能性远高于咨询律师或会计师。未来，立法者甚至可能直接以计算机代码的形式起草税法条文——如此一来，TurboTax的律师与工程师目前必须完成的“将法律规定转化为软件程序”这一解读环节，便会被彻底省去。（中国现在的个人所得税就是官方设置的，直接代码化）</p>
    <p>【本文认为法律自动化在可行性方面的局限】</p>
    <p>然而，立法者与监管者在试图将法律义务编码为软件程序时，应保持审慎态度。尽管计算机代码与人类语言均能实现沟通功能，但二者所具备的“功能属性”（affordances）截然不同，且在诸多方面互斥。代码的目标是消除模糊性与灵活性——而这两种特性恰恰是包括法律语言在内的多数人类语言的典型特征。正如试图用“规则”完全取代“标准”的努力均以失败告终，绝大多数将法律规则重写为代码的尝试，也终将面临同样的结局。（这个论断成立的前提是代码是rule形式的，不具有灵活性。但机器学习的成果是否如此？）</p>
    <p>【支持法律完全自动化的观点和理由】（现有研究的综述）</p>
    <p>诚然，技术已在协助民事律师履行其作为代理人与咨询顾问的传统职责，且未来仍将继续发挥这一辅助作用。但技术能否完全取代律师？对于许多将工业领域趋势套用于法律职业的未来主义者而言，答案是斩钉截铁的“能”。法律未来主义者预测，软件不仅能帮助律师检索与案情摘要相关的案例，甚至能自主撰写法律文书。部分人更预言“法律奇点”（legal singularity）的到来——即“当海量数据积累与推理方法的大幅改进，使法律不确定性彻底消失之时”。对许多记者而言，这类观点极具说服力，进而催生了大量关于“律师的终结”与“大型律所的消亡”的报道。</p>
    <p>【理由】</p>
    <p>法律未来主义者的观点建立在法律软件供应商的主张之上——这些供应商往往将通常的法律实践贬低为充斥着低效问题，其目的通常是通过对比凸显自家产品的优越性，以更好地推广销售。</p>
    <p>这两个群体均将法律服务自动化视为一种解决方案，认为它能推动司法可及性（access to justice）、降低法律成本，并促进法治发展。</p>
    <p>【降低法律成本，提升司法可及性】：法律未来主义者将这类技术发展描述为“法律民主化”，认为它能赋予普通民众更多权利。他们的论述既利用了保守派支持市场、反对职业垄断的论调，也迎合了左翼对精英群体的不信任态度。</p>
    <p>【促进法治】法律未来主义并非仅仅被描绘成专业服务市场竞争日益激烈下的必然结果，相反，它被推崇为具有规范层面的可取性——是一种“新型法律形式”，据称这种形式“既能兼具规则与标准的所有优势，又能规避二者的弊端”。</p>
    <p>法律未来主义者倾向于将“把法律义务转化为计算机代码”视为实现法治的积极进化步骤。[15]他们认为，人类律师可能会在事实认定上出错，或曲解先例；人类法官则可能受无关因素干扰，或存在偏见。[16]因此，法律自动化的推动者往往将自身工作视为“让法律体系摆脱个体局限性”的又一重要进展——即让法律体系不再受制于其中任何特定个体的易错性。[17] 对于 “法治而非人治” 这一常被引用的理想目标，一种直白的实现路径便是：完全摒弃负责执行或解释法律的人类。[18] 例如，由闯红灯摄像头自动判定并处以不可上诉的罚款，且直接从驾驶人的银行账户中扣除——这便是法律完全自动化的典型场景，不受任何特定决策者偏见的影响。</p>
    <p>【作者对上述观点的回应】</p>
    <p>当然，这种方式只是将个人责任从律师、监管者与法官身上，转移到了为“潜在替代者”编写代码的人身上。（<span style="color:Blue;">算法并非天然产生，裁决权从法律从业者转移到了程序员等手中，这可能还不如法律从业者。</span>）除非某种“主算法”能自主编写后续程序，否则人类始终要对法律裁决负责。[19] 要让法律自动化真正遵循法治原则，“法治而非人治”这一格言必须辅以一项新承诺——即“人治而非机治”。[20]若不将算法的判断与解释归责于特定个人，也不要求这些人负责解释相关判断，法律自动化便会破坏问责制的基本原则。（<span style="color:Blue;">必须有人为算法决策结果负责，这里结合算法避责现象。</span>）</p>
    <p>本文阐述了语言通常如何构成法律与法律裁决的核心。语言并非只是法律可采用的多种形式之一，而是唯一能实现法治基本原则的形式。认识到语言的这一作用，应当为法律自动化的未来发展提供指引。同时，这种认识也能平衡法律未来主义者日益盛行的论调——它明确指出，当社会将“权威阐释权利与义务”的更多方面让渡给计算流程时，我们会失去什么。</p>
    <p>【本文的结构】</p>
    <p>替代性法律自动化的设计目的是“取代”律师，而非仅仅“协助”律师。[21]第一部分探讨了替代性法律自动化已广泛渗透的三个领域：如今为数百万美国人准备纳税申报的软件、像LegalZoom这样通过与客户的计算机化交互起草遗嘱与合同的公司，以及像DoNotPay这样引导用户申诉停车罚单的聊天机器人。这些法律科技都让信息获取变得更加普及。但与此同时，它们也可能误导用户对自身权利与义务的认知，且会通过限制性服务条款，剥夺用户就此类损害寻求赔偿的机会。法律语言的丰富性与复杂性，远非这些简单程序所能呈现。</p>
    <p>尽管当前用技术替代律师的尝试规模有限，却已存在上述及类似问题，但计算机科学家与法律学者仍在推动更具雄心的替代性自动化项目。第二部分将介绍其中三项举措及其缺陷。在每一个案例中，起初看似只需将语言简单转化为计算机代码的法律问题，最终都取决于远比这复杂的社会与政治关系。语言所具备的灵活性与开放性，为维持这类关系提供了必要的应变空间。然而，许多法律未来主义者仍将“嵌入代码的自动执行法律”视为法律科技的终极目标，并大力推崇这一愿景。</p>
    <p>第三部分提出了一种替代路径：将技术视为“补充律师技能”而非“取代律师”的工具。该部分借鉴人机交互研究中常见的“人工智能（AI）”与“智能增强（IA）”的区分，提出了“互补性（而非替代性）法律自动化”的原则。这种互补性路径不仅有望更好地为客户服务，还能更充分地实现法治价值。</p>
    <p>法律领域复杂多样，其服务范畴既包括最基础的行政流程，也涉及关乎监禁与自由的重大事项。因此，软件与机器人在“起草、解释和执行法律”方面的应用，其可接受程度会因场景不同而存在差异，这一点不足为奇。用聊天机器人办理钓鱼执照是合理的，未来几年我们有望看到更多更完善的此类“公民科技”案例。[22]另一方面，即便是最热衷于推动法律自动化的支持者，也不希望看到由机器人法官或陪审团作出监禁判决。在这两种极端情况之间，还存在一些更难界定的问题，下一部分将对此展开讨论。</p>
    <p>这些应用程序填补了法律服务市场的空白。总体而言，当前人类某项工作完成得越糟糕，相比之下机器人的表现就显得越出色。对普通美国公民来说，日常与法律机构打交道的经历，轻则令人厌烦，重则让人尴尬不适。车辆登记、所得税计算、经济援助申请——每一项都可能轻易陷入文本构成的复杂迷宫，其间还穿插着与粗鲁且超负荷工作的行政人员之间的不愉快互动。如今，软件与应用程序开发者正试图通过创新的客户服务方式，减轻这种负担。然而，这些干预措施各自都存在意想不到的后果，从而限制了其价值。</p>
    
    <h3>第一部分 现有的替代性法律自动化应用</h3>
    <p><span style="color:Blue;">这部分讨论的均是面向公众提供的自动化法律服务，而非法院的法律决策。</span></p>
    <p>最具发展前景的法律自动化形式，面向的是“需要律师却无力承担费用”的群体。例如，在许多低收入社区，成千上万的儿童因售卖大麻、故意破坏财物等行为留下了少年犯罪记录。[23] 各州均认可，这类记录不应在当事人成年后继续困扰他们，且几乎所有州都推出了某种“记录封存（expungement）”程序，用于封存此类记录。[24] 律师通常能较快办妥记录封存手续，但并非所有人都有机会聘请律师。因此，公益律师与技术人员开发了如“马里兰州记录封存”这类应用程序（专为马里兰州居民设计），将“申请简单记录封存”的大部分流程实现了自动化。[25]</p>
    <p>遗憾的是，一旦法律问题超出“判断某份犯罪记录是否符合封存条件、何时可封存”的范畴，基于软件的解决方案便很容易失效。本节将探讨一个复杂问题：如何用计算机代码转化法律条文的要求，同时让非专业人士也能理解。</p>
    
    <h3>第二部分 未来替代性法律自动化的计划</h3>
    <p>（<span style="color:Blue;">替代性法律自动化是指基本完全自动化的模式，大部分工作依靠自动化完成。</span>）</p>
    <p>【法律自动化在低风险、人类提升有限的领域具有较高正当性】</p>
    <p>替代性法律自动化最普遍的案例存在于消费领域，例如税务、遗嘱拟定与交通纠纷等领域。即便在这些相对平稳的实务领域，这类自动化也引发了关于 “非预期后果”与“消费者保护” 的重大伦理担忧。但总体而言，当案件涉及的风险较低，且寻求更优替代方案的可能性也微乎其微时，这些领域的替代性法律自动化或许是一种值得肯定的现象。多项研究表明，美国中低收入群体存在大量未被满足的法律需求。[78] 对许多公民乃至小型企业而言，法律软件可能是他们唯一能获取的法律咨询形式。（<span style="color:Blue;">或许可以形成分层次的法律服务，自动化便宜，人类法律服务昂贵？后文作者有对此的回应，认为人们无法像衣服一样辨别法律服务的好坏。这个论证值得思考。</span>）</p>
    <p>消费服务领域的早期成功，激励了新一代法律自动化推动者，促使他们呼吁企业与政府将曾由律师（或其他负责解读、适用法律的人员）承担的工作标准化、计算机化。[79] 相较于 “推动司法可及性”，这一主张的核心吸引力更偏向 “降低法律支出”。[80] 在全球竞争日益激烈、政府财政收入下滑的时代，成本节约无疑是极具说服力的理由。</p>
    <p>【法律服务自动化的风险】</p>
    <p>但在许多情况下，法律服务自动化实则是将成本与风险“外部化”——转嫁给了客户、公民及商业竞争对手。人员成本的即时节省显而易见，而长期风险虽具有不确定性，却真实存在。（这里所说的长期的风险/成本究竟是什么？）这些成本不仅已在现有法律自动化项目中被记录在案，即便在那些旨在加速法律流程自动化的理想化提案中，也同样可预见。（<span style="color:Blue;">下文将介绍一些加速法律流程自动化的未来提案，并借此说明那些长期风险/成本。</span>）</p>
    
    <h4>A. 隐私合规中的需求提取</h4>
    <p>在法律未来主义者看来，法律流程本质上具有算法属性：通过应用既定规则（即法律），数据（即事实）可被转化为输出结果（即判决或结论）。[81] 这种模式在金融合同领域最容易想象。例如，某份合同可能约定：若黄金价格跌至每盎司 800 美元以下，一方需以每股 10 美元的价格向交易对手方购买 100 股股票。只要双方能就以下三点达成一致 —— 黄金价格的权威数据来源、股票与购股资金的托管方式，以及黄金价格触发条件满足后股票所有权自动转移的机制 —— 这份合同就能实现有效的自动化。</p>
    <p>对追求效率的人而言，将交易拆解成数十甚至数百个此类组成部分，似乎是极具吸引力的目标。然而，一旦法律场景中加入更多复杂性因素（如管辖权或宪法层面的考量、优先适用原则，或法律条文的例外规定），整个体系便会变得难以处理。这也是如今大量资源被投入到企业对企业（B2B）交易相关法律技术开发中的原因之一。（<span style="color:Blue;">算法不能完全替代法律过程的原因1：法律规定充满着例外</span>）</p>
    <p>【例证】</p>
    <p>【算法自动管理数据的访问权限，以保证数据处理符合法律规定】</p>
    <p>例如，在卡内基梅隆大学计算机科学系的特拉维斯・布鲁（Travis Breaux）带领下，由程序员与律师组成的团队将隐私法规合规问题建模为 “输入（数据）与输出（对数据共享范围及程度的特定限制）” 问题。[82] 依据联邦健康隐私法，一家大型医院可能需要与从信用卡公司到云服务商等各类企业签订超过 500 份 “业务伙伴协议”。[83] 这类合同的核心目的，是明确作为 “受管辖实体”（covered entity）的医院，可向其他实体传输个人健康信息的范围限制。[84]</p>
    <p>【实现方式：拆解法条，将其转化为代码】</p>
    <p>布鲁及其合著者对相关法规与政策进行了分析，将其拆解为 “构成性语义”（特定术语的含义）与 “句法结构”（法律规定的术语间关联关系）。[85] 他们通过编程让计算机针对特定场景生成合规输出结果。[86] 例如，某患者在其初级保健医生诊所的健康记录中可能包含 “糖尿病” 相关信息。一旦该糖尿病数据录入相关数据库，系统便会对其叠加特定限制：患者本人或其他为该患者提供治疗的医生可随时访问该数据；[87] 而该数据若用于营销目的，则必须获得患者的明确同意。</p>
    <p>【将自然语言拆解转化为代码的方法】</p>
    <p>方法一：把法律条文的规定拆解为特定的组件，再把这些组件分别转化为代码。</p>
    <p>为将合同与法律条文转化为计算机代码，布鲁及其合作研究者采用了 “语义参数化”（semantic parameterization）方法 ——“即把法规文本中的权利与义务重新表述为‘受限自然语言陈述’（RNLS），以描述独立的行为活动”。[89]将法律要求拆解为组成部分，并为这些部分提供严谨定义，这种做法既是宝贵的教学工具，也是有效的研究手段。它有助于细致解析法律术语，还能引发关于“阅读”“通知”等术语在不同场景下含义的深度思考，是梳理法规或法条“命题表述内容”的实用方法。（<span style="color:Blue;">拆解自然语言的法条有助于理解法律的确切含义</span>）</p>
    <p>通过例证来分析该方法的可行性和局限性：</p>
    <p>例如，某条法规要求医疗服务提供者必须 “张贴通知供个人阅读”，该要求会被拆解为以下参数：要求的主体（医疗服务提供者）、行为（张贴）、对象（载明数据政策的通知），以及目的（让个人阅读该通知）。[90] 而这一“目的”本身又可拆解为一组新的基础构成单元：主体（患者个人）、行为（阅读）、对象（该通知）。</p>
    <p>然而，即便是 “张贴通知” 这样看似简单的规定，其涉及的术语含义仍存在进一步的模糊性：通知中必须包含哪些具体内容？当法律规定通知 “供个人阅读” 时，是否要求服务提供者承担 “确保个人实际阅读” 的义务？又该如何验证这一义务已履行？</p>
    <p>诚然，这类问题并不会让医院或日间手术中心的普通合规人员束手无策。实务中，流程通常是：拟定通知、患者签字确认已阅读、随后提供医疗服务。但这些通知也需根据不同场景调整：例如，在有大量非英语母语者的环境中，通知的设计与呈现方式必须区别于无此类人口特征的场景，才可能充分反映该群体的关切。[92] 若患者拒绝签字，该如何处理？通过患者就诊前或就诊后发送电子邮件的方式，能否满足 “张贴通知” 的要求？</p>
    <p>理论上，针对这些可能出现的情况，我们可以设计算法化的应对方案，并将其编入自助挂号终端。[93] 但现实中更可能发生的场景是：拒绝签字的患者在自助挂号终端前不知所措，最终仍需医疗服务提供者的工作人员介入协助。此时，自动化系统又该如何应对？（<span style="color:Blue;">完全的自动化合规不可行，总有一些情况需要人类的介入。但自动化可能能够解决应对大多数情况？</span>）</p>
    <p>《健康保险流通与责任法案》（HIPAA）内容极为复杂，很难想象如何将其全部转化为软件代码。[94] 而 HIPAA 仅是健康隐私法的冰山一角 —— 该领域还涵盖各州层面的普通法与制定法。如今，医疗行业企业希望通过对法律要求的 “跨法域分析”，全面确保隐私合规。[95] 这至少需要纳入以下主体的隐私限制规定：美国各州、联邦政府，以及企业可能涉及数据传输的其他国家 / 地区的政府。[96]（<span style="color:Blue;">现实中，同一行为、领域的法律要求多样繁杂，并且要做到合规，需要思考的因素并非完全预先确定、封闭的范围，要把这些繁杂的法规、考量因素完全转化为代码，是非常困难的。</span>）</p>
    <p>方法二：用大数据等统计算法对现有的隐私政策、法律规定等进行文本分析，找出合规的要求。但这存在两方面的局限性：1、文本分析可能无法发现识别出规定之间的潜在冲突；2、解决这些冲突需要人类做出权衡判断。</p>
    <p>布鲁团队也对数据集展开了研究，包括 “从 100 多份隐私政策中挖掘出的 100 个最常出现的半结构化目标”。[97] 其研究路径颇具雄心：布鲁与另一位合著者 “计划在金融监管与航空标准的语境下，进一步验证该方法、启发式规则及模式，以确定其在医疗领域之外的适用性”。[98] 隐私与网络安全要求是这类自动化的核心目标领域。[99]</p>
    <p>然而，负责控制成本的总法律顾问们在为合规自动化兴奋之前，应当认清这项研究的局限性。布鲁等人承认，“若缺乏进一步验证，将目前人工执行的工作自动化还为时尚早”。[100] 更值得警惕的是，他们还指出，“在识别权利与义务之间的冲突时，仍需考虑约束条件的作用。而在本文研究中，我们仅通过观察语义模型中的否定表述与类型相似值，识别出了一些简单的冲突”。[101]（<span style="color:Blue;">1、是否能够识别出法律要求之间的潜在冲突？可能只能识别简单的。</span>）</p>
    <p>这类冲突在信息法领域十分常见。例如，同一家企业可能同时承担两项义务：一是 “数据保全义务”（nonspoliation and preservation duty），要求留存数据；二是 “数据最小化义务”，可能包含需尊重客户或商业伙伴提出的删除数据的要求。[102] 妥善处理这类冲突是律师的核心常规工作，且在制定任何数据留存策略时，都需要人类通过判断来权衡其中涉及的各类风险。（<span style="color:Blue;">2、法律规定的要求之间可能存在矛盾、冲突的地方，要兼顾这些不同的要求，就需要根据场景做出适当的取舍和平衡，这种微妙的判断目前只有人类能够做到。</span>）</p>
    
    <h4>B. 作为语言机器人的智能合约</h4>
    <p>利用代码和一系列识别机制来自动执行合同条款。</p>
    <p>DVD 的授权播放范围可能仅限美国与欧洲，随后会通过 “编码” 使其仅能在上述地区播放，而无法在其他地区使用。[104] 若由人工为用户播放该 DVD，此人可能会要求查看 DVD 的使用条款副本与购买凭证，以确认其在特定地区的播放权限是否合法。而计算机则需要将这类条款转化为自身 “可理解” 的语言；换言之，嵌入 DVD（及运行 DVD 的程序环境）中的法律条款，必须能触发与之交互的技术系统产生可预测的反应。</p>
    <p>……如果法律所明确的要求是简单的二元选择（非此即彼），且属于易于编程实现的目标，那么这种自动化或许仍有光明的前景。……这类工具还能重新表述某些法律条文，将其转化为普通人可理解的合规要求。[108]（<span style="color:Blue;">这类智能合约适用于简单的if-then逻辑的条款，其简单的前提条件成就时自动执行条款。</span>）</p>
    <p>此外，若合同能通过基于代码的 “自动” 执行机制获得一定程度的保障，当事人可能会更愿意签订合同。[109]……在古迪纳夫与弗拉德看来，一套足够完善的自动化系统能同时提升签约双方的信任度与交易效率。[117]（<span style="color:Blue;">自动执行的合约能够降低违约风险，这属于法律自动化中可预期性强的优点的体现。</span>）</p>
    <p>例证：</p>
    <p>在简单的供应链管理场景中，智能合约确实展现出了一定的应用潜力。[110] 试想这样一个场景：一艘货轮驶入港口，集装箱内装有 50 吨白糖。假设已部署能够识别白糖、检测其重量与质量的传感器，便可以设计一套自动化交易流程。从某种意义上说，几乎所有在亚马逊购物的人，在 “一键下单” 后都会经历类似的自动化交易过程。[111] 正如美国商品期货交易委员会（CFTC）前委员近期所言：“当智能合约的触发条件依赖现实世界数据（例如某一时刻商品期货的价格）时，我们可以开发各方认可的外部系统 —— 即‘预言机’（oracles）—— 来监控并验证价格、履约情况或其他现实事件。”</p>
    <p>【智能合约的局限性】</p>
    <p>当涉及更复杂的产品时，交易自动化可能会陷入困境。例如，与白糖这类标准化商品相比，鸡肉的评估（甚至称重）难度要大得多。在经典判例 Frigaliment Importing Co. v. B.N.S. International Sales Corp.[113] 中，双方当事人就合同中 “鸡肉” 一词的含义爆发了激烈争议。目前，对物理实体的自动化评估仍受两大问题制约：一是数据缺失，二是人类对术语含义的理解存在分歧（这种复杂性往往混乱且难以统一），导致评估效率低下且结果不准确。[114]（<span style="color:Blue;">if条件的判断在现实中可能存在歧义，仅适用于1、机器能够检测、2、评价标准明确的情况。如这里列举的标准化商品。</span>）</p>
    <p>因此，法律自动化推动者将大部分精力集中在了与线上活动相关的合同上。（<span style="color:Blue;">线上的活动满足上述两个条件，1、线上的活动天然会被电子化记录，计算机可以读取相关数据来判断某件事是否发生；2、由于都是数据，所以可以基于数据形成固定的判断标准。ps：也不尽然，例如自动化审查内容就无法形成明确、标准化的判断标准。</span>）</p>
    <p>例如，佛蒙特法学院的奥利弗・古迪纳夫（Oliver Goodenough）与美国金融研究办公室的马克・弗拉德（Mark Flood）提出了 “智能合约即‘自动机’（automatons）” 的理念 —— 一旦金融协议被转化为可计算的形式，智能合约就能作为自动执行交易的工具。[115] 二人认为，“一份撰写完善的金融合同，其核心法律结构遵循‘状态转移逻辑’，这种逻辑可通过数学形式化为‘有限状态机’（也称为‘有限状态自动机’）”：在该模型中，“自动机定义了金融关系可能处于的状态（如‘违约’‘逾期’‘正常履约’等），同时定义了一组可触发状态转移的‘事件集合’（如‘收到付款’‘到期日届满’等）”。</p>
    <p>未能履行合同条款的后果问题，不仅本身颇具难度，更对诸多法律领域自动化的未来走向具有重大影响。现实中，违约总有各种潜在借口 —— 例如，银行可能未能成功转账、新员工可能误改了账户信息，或是保险公司调整了自身账户设置导致付款困难。对于如何公平解决这类情况，我们每个人都有直观的判断；更准确地说，我们能大致知晓这类纠纷应依据合同或法律条文的哪项规定来处理。[119] 但要将这种判断力（更不用说验证每种情况事实依据的能力）编写进单台计算机，甚至编写进一个能够监控所有相关方的网络系统，却是一项极为艰巨的任务。（<span style="color:Blue;">事前拟定好的代码化条款，如果遇到变更怎么办？一般的做法是交给人类来判断，需要人类的介入。</span>）</p>
    <p>这正是明智的程序员可能会选择将纠纷直接移交人类调解小组处理的原因之一 —— 调解小组可负责快速判定：航空公司对付款延迟的解释是否合理，能否允许其继续履行合同；或是该解释是否构成保险公司终止合同的正当理由。换言之，人类为自动化法律系统提供补充，很可能是对所有相关方而言最优的结果。这种模式在自动化发展史上反复出现：例如，20 世纪 90 年代计算机首次击败国际象棋特级大师；[120] 到 21 世纪 00 年代中期，已没有任何特级大师能战胜最顶尖的象棋程序。[121] 但直至今日，“人类 + 机器” 的组合仍能击败最优秀的象棋程序。[122] 类似的协作模式在法律领域（尤其是纠纷涉及高风险时）也很可能被证明是最优选择。（<span style="color:Green;">人类与机器的配合协作是比完全自动化更优的模式。但问题在于，人类与机器如何协作，是所有按照决策流程分工？如所有的决策都交由人类做最终决定。还是按照决策类型来分工？如简单决策交给机器，复杂决策交给人类。不同的分工模式背后的理论依据、法学正当性在何处？</span>）</p>
    <p>【一些监管机构要求金融交易合同代码化，目的在于提高交易的透明度、便于直接监控】</p>
    <p>然而，监管机构一直在敦促（部分情况下甚至强制要求）金融机构将其合同约定以代码形式呈现。美国商品期货交易委员会（CFTC）与美国证券交易委员会（SEC）的工作人员在一份报告中指出：“当前技术已能够通过一套通用的计算机可读描述来呈现衍生品合约，[且] 这种描述的精确性足以满足两项需求 —— 既可用以计算净风险敞口，也可作为具有约束力的法律合同的部分内容，甚至全部内容。”[124] 这种乐观态度也体现在监管机构对其他证券类型的监管举措中。例如，SEC 近期敲定了一项规则，要求部分资产支持证券（ABS）的发行方提交 “可下载的 Python 源代码”，以此体现嵌入该证券产品中的合同约定。</p>
    <p>尽管监管层面已有上述进展，但要求 “提交证券合同现金流条款的‘瀑布式’计算机程序”，对 SEC 而言仍是一项 “悬而未决” 的提案。[126] 乍看之下，SEC 的这种克制态度令人费解 —— 毕竟，资产支持证券（ABS）中现金流的不确定性，正是 2008 年金融危机的诱因之一；而旨在推动 SEC 加强 ABS 市场监管的《多德 - 弗兰克法案》（Dodd-Frank Act），其出台的核心动因也源于此次危机。[127] 然而，SEC 的犹豫，实则反映了代表金融机构的意见方提出的合理担忧。例如，摩根大通（J.P. Morgan）提出质疑：“每一笔 ABS 交易都有其独特属性”，若将每一笔新交易都转化为 Python 代码，不仅成本高昂，其实际效用也存疑。[128] AmeriCredit 则直言不讳地表示，公司 “不应被迫预测并为‘瀑布式’付款的所有细微可能情形编写程序”，因为其业务是 “收购并管理汽车贷款，而非软件开发”。[129] UBmatrix 也认为，相较于直接以文本形式表述义务，将义务转化为程序在准确性或透明度上并无优势。[130]</p>
    <p>在针对 “资产支持证券（ABS）现金流自动化” 提案的各类意见中，存在一个共同核心观点：SEC 推行的 “将法律协议转化为软件” 要求，本质是 “一刀切” 式的标准化方案，但市场实际情况要么无法实现这种标准化，要么使其成本过高、不具备可行性。[131] 此处计算机化面临的阻碍，对法律流程自动化的支持者而言，应是一则警示 —— 这些支持者常指责法律行业提供 “定制化”（bespoke）服务，声称 “规模化服务完全可行”。[132]（<span style="color:Blue;">从这个角度讲，法律自动化就是把原本个性化、定制化的服务统一化、标准化。</span>）</p>
    <p>“定制化” 这一比喻在他们的论述中发挥着重要作用，但推崇者却很少深入剖析其内涵。定制西装是奢侈品，多数人并不需要：极富人群可能会为衣物定制专属版型，但社会中其他人穿成衣便已足够。然而，当涉及稍有复杂度的纠纷时，“服装制造与法律服务的类比” 便不成立了。任何人都能对着镜子判断衣服是否合身，但法律服务属于 “信任品服务”（credence service）—— 普通人很难判断自己是否获得了优质的法律建议。[133]（这类信任品服务有什么特征，应该受到何种约束、规制？法律服务是否属于这类？有待进一步了解。）</p>
    <p>因此，当初创公司 Deftr 推出服务并打出 “法律不是劳力士（law is not a Rolex）” 的口号时，我们应保持警惕：该口号暗示 “民主化的法律应像如今获取个性化时间一样便捷——只需‘看一眼手机’”。[134] 这类表述更多反映的是企业的商业野心与反劳动者理念，而非对法律市场的扎实洞察。</p>
    <p>【在历史上就有过机器替代律师的讨论】</p>
    <p>20世纪30和60年代，美国主流经济评论员都曾预言，随着机器取代工人的趋势加剧，永久性大规模失业将不可避免 —— 而这种 “商品化”（指工作被机器标准化替代），正是部分未来主义者针对律师职业所预测且推崇的前景。[135]</p>
    <p>就像大众媒体与行业刊物上那些探讨 “律师行业终结” 的文章一样，这类预言的逻辑相当简单：（1）软件程序在识别文本模式、甚至理解文本含义方面的能力正不断提升；（2）法律实务的核心，大多是将规则适用于具体事实情境，或是预测相关权威机构（如法院、监管部门）会如何将规则适用于某一情境；（3）计算机程序员同样在进行 “规则适用于事实” 的工作，且随着编程技术的发展，代码将接管越来越多此类 “规则适用” 场景。但即便看似简单的场景，也可能存在层层复杂性与不确定性 —— 这些复杂因素根本无法通过代码妥善嵌入软件或表格中。[136]（<span style="color:Blue;">一方面，法律具有复杂性，技术上难以实现；另一方面，法律具有伦理性特征，不同于单纯的专业应用</span>）</p>
    <p>【作者对上述逻辑的回应】</p>
    <p>首先，我们来思考 “含义解读” 这一问题。法律流程的核心在于 “阐释” 与 “裁判”—— 这与多数法律自动化中常见的 “预测建模” 和 “模式识别” 有着本质区别。法律决策者的工作，绝非简单地确保某一结果（有责或无责、有罪或无罪）与先前类似案例的表述相匹配。相反，决策者需要评估“具体情境下事实的含义”与“具体情境下法律的含义”。在非法律从业者眼中看似常规的法律工作，实则可能涉及需要“政策判断”“专业智慧”的场景，且承担着类似“立法”或“治理”的责任。（<span style="color:Blue;">法律决策并非只要求该判决与之前的类案保持一致/同一种模式，这是机器学习模式识别所期望达到的目标。还要求决策者是真实地在具体场景下考量了事实和法律的含义之后，做出的判断。并且秉持着立法/治理的智慧做出这种判断。本文这里潜在的意思是法律决策不是一个只是结果导向、表观主义的任务，即便算法通过模式识别与人类达成了相同的决策结果，可能也会因为缺少过程中“有意义的思考”而欠缺正当性。人类是通过有意义、有目的的思考来得出结论的，而算法虽然能够通过词频等统计学方法得出类似的结论，但其本质上是没有理解案涉事实和法律规则的。</span>）</p>
    <p>……在此领域具备基本执业能力的律师都清楚，“抗辩理由属于‘管辖权性质’（即法院必须主动审查）还是‘可放弃性质’（即当事人未提出则视为放弃）”，对客户而言是极度紧急的关键问题。[146] 遗憾的是，如今许多立志将法律咨询计算机化的程序员，要么不知道这些基础术语，要么未能理解其重要性。（<span style="color:Blue;">算法对法律过程的模拟/代替至少应该建立在对法律的理解之上，这是对机器学习模式独有的批评，专家系统不存在这种问题。</span>）</p>
    <p>当然，除了止赎行业从业者，很少有人会认可 “20 天规则” 的严苛性，或法律体系中类似的僵化规定。在此提及这些规则，是为了指出：硅谷初创企业的思维模式，在当代法律实务的诸多方面都存在极大的不适用性。[147] 法律行业媒体（其资金往往来自法律科技公司的广告费），常常笼统地将具有 “颠覆性” 的初创企业描述为 “为僵化的法律行业注入新鲜空气”。[148] 它们却忽略了一个事实：优质的法律实务建立在 “谨慎、细致与反复校对” 之上，因为法律领域的失误往往无法挽回——例如，提交的法律文件有页数限制；[149] 庭审中未提出的许多问题，在上诉阶段不得再提出；[150] 在某些情况下，即便存在 “实际无罪” 的证据，也无法挽救被错判死刑的囚犯。[151]（法律实务是一件有着严重后果的活动，轻易、不审慎的创新、尝试、颠覆都是危险的。这区别于其他行业自动化的创新尝试。）</p>
    
    <h4>C. 作为产权登记替代方案的区块链</h4>
    <p>暂略。主要表达的意思是一些人主张用区块链技术的不可篡改、自动记录的特性来代替一些备案、登记等法律事务。但作者认为区块链技术可能被黑客攻击，也并非完全不可篡改；人类现实活动纷繁复杂，总有一些特殊的情况需要人类介入系统。</p>
    
    <h3>第三部分 推动法律领域的互补性自动化</h3>
    <p>作者主张的方案：人类与自动化技术协同，算法强化人类的能力，共同做出更好的决策，而不是替代人类决策。</p>
    <p>……法律未来主义者对经济进步的片面构想，反映出他们对法治rule of law的规范性解读并不完整incomplete——这种解读对法律制度的期待既过高，又过低。无论法官与监管者追求何种其他规范性目标，他们都应恪守法治原则。</p>
    <p>理查德·法伦（Richard Fallon）指出，在当代法理学中，至少存在三种截然不同的对“法治”的理想型解读。法律自动化推动者往往聚焦于历史主义解读（该解读将法治与“由合法立法机构在适用于具体案件前制定的规范所构成的统治”相关联）与形式主义解读（该解读将“‘法律’的理想形式——即便非必要形式——定义为‘规则’，即被视为在适用前已存在、且能决定恰当行为或法律结果的明确规定”）。[227] 若联邦健康隐私监管真能简化为编码于软件中的“要求提取”，那么从历史主义与形式主义的法治概念来看，这种编码或将成为法治领域的一项切实进步。此时，法律将能像软件指令一样具备可执行性。同理，将交通规则转化为一系列聊天机器人提示，即便无法直接实现法律的适用，也能让法律呈现出清晰明确的形态。</p>
    <p>然而，法治还存在另一种解读视角，即“法律过程理论（Legal Process）视角”。（强调法律的过程）相较于历史主义或形式主义视角，该视角的内涵更宽泛，且形成时间更晚。</p>
    <p>正如法伦（Fallon）所阐释的：“法律过程理论视角认为，要满足法治对‘法律’的核心要求，需具备以下几方面要素的结合：（1）法律规范的制定与适用过程需具备程序公正性；（2）法律理念与合理性理念之间存在（公认的）内在关联；（3）需通过理性论证，阐明已确立的、预先存在的法律权威渊源，与具体案件中权利义务的判定之间的联系；（4）需以司法审查作为保障——确保立法、行政及管理决策者的决策过程符合程序公正，并经过理性审慎的考量。”</p>
    <p>与历史主义学派和形式主义学派相对简洁的解读相比，这一详尽的定义或许显得晦涩。若说前述两种学派强调的是法治rule of law中“rule”的层面，那么法律过程学派则将“law”视为法治的核心构成。作为一种社会制度，法律具有多面性，且深植于特定的政治体系与传统之中，例如上诉权与决策说明制度便属此列。就像智能合约这类法律科技，若将法律关系简化为“在适用前即已存在、且能决定恰当行为或法律结果的明确规定”（这正是形式主义法治观的典型体现），那么它便不太可能满足法律过程学派法治观所包含的、复杂的审查与上诉标准。[230]</p>
    <p>当解释层面的争议出现时，法律过程学派的法治观要求为争议各方提供“通过理性论证阐明已确立的、预先存在的法律权威渊源，与具体案件中权利义务判定之间联系”的机会——而非通过代码对案件作出简单处置。[231]此外，像前文讨论的“DAO黑客事件”后所采取的那种临时干预措施，也无法保障法律过程学派法治观所倡导的“程序公正与理性审慎考量”。[232]单方面动用远超对方的法律科技资源，同样会破坏法律过程学派所重视的对话机制与公平博弈原则。</p>
    <p>Fallon主张，应将“法治”传统中多方面的内涵整合为一种完善的混合理论，以充分体现各理论流派的优势。[233]受其思路启发，本章将提出一系列原则，为法律自动化的未来发展提供指引——这些原则旨在培育和提升律师的专业技能，而非贬低或弱化其价值。</p>
    <h4>A.智能增强作为规范性理想（价值目标）Intelligence Augmentation</h4>
    <p>趁手的工具能让工作变得轻松得多，甚至充满乐趣。</p>
    <p>比如卡车司机，定速巡航功能可以让他的脚不用一直踩在油门上，有时间活动一下、缓解抽筋。[234] 自动变速箱则让高低挡位切换变得更简单。[235] 防撞软件还能提醒他盲区里有车辆。[236] 技术能极大简化这份工作——直到它完全取代司机为止。[237]</p>
    <p>在“帮助劳动者的发明”与“彻底取代劳动者的发明”之间，或许存在一种微妙的平衡。不过，经济学家认为这种区别对价值界定至关重要，他们将前者称为“劳动的互补品”，后者则是“劳动的替代品”。[238] 在计算机领域，人工智能（AI）研究的重点一直是能替代人类认知与注意力的技术。[239] 例如早在20世纪60年代，麻省理工学院的机器人专家就开始研发机械哨兵，以替士兵承担在薄弱据点站岗的枯燥且危险的任务。[240] 但看待哨兵机器人还有另一种视角：它并非用AI取代士兵，而是提升士兵作战效能的又一工具。军队不必将步兵或哨兵视为“只要新工具能模仿其核心功能，就可迅速替换的‘无人机式’角色”，反而可以将人员培养成“操作日益精密的机器的专业操作员”。传感器与计算机可被设计成“第二双眼睛和耳朵”，快速处理威胁等级及其他数据，为士兵的行动提供更充分的信息支持。这便是一种“智能增强（IA）”，相比AI，它启发的项目数量要多得多。</p>
    <p>人工智能（AI）与智能增强（IA）研究者之间的良性竞争，为法律自动化未来的政策辩论提供了新视角。软件往往无法提供律师所能提供的全方位服务与保障。[242] （<span style="color:Blue;">这里想到的思考是：软件/算法究竟有没有能力提供律师的服务，这是一个事实问题，随着技术的发展，事实会给出答案，也不是法学所主要思考的问题。法学应该思考规范性问题，即就算软件具备了替代的能力，法学规范上是否应该允许其替代？应然的、规范性问题是需要考虑研究的。即哪些环节、功能是人类必不可少的？</span>）尽管如此，联邦政策制定者近期却对那些试图明确区分“自动化法律咨询”与“律师直接提供的法律建议”的州政府施加压力。 例如，当北卡罗来纳州试图更新其对“基于软件的法律服务”的监管规则时，联邦贸易委员会（FTC）与司法部（DOJ）公开表态批评该州，并威胁要对其采取反垄断行动。[243] 这两家机构将此举定性为“打击律师自我保护”，但其干预行为在经济政策层面缺乏有力依据，且明显未意识到（或完全忽视了）关于自动化隐患的相关文献。[244] 他们似乎执意要推动软件成为律师的替代品，即便这类软件的销售方常常向终端用户强加免责条款（或其他责任限制条款）。[245] 此类条款会过早终止因“不良结果”引发的诉讼——而这类诉讼本可帮助律师与消费者更好地理解“用AI处理法律事务”所涉及的风险。[246] 至少，联邦反垄断政策制定者应推动各州禁止此类条款，以便为法律服务市场营造更公平的竞争环境。</p>
    <p>计算机科学研究者也应更开放地看待一个事实：法律所具有的不确定性与灵活性，是更适合通过人类（而非算法）方式处理的特征。在早期的专家系统迭代中，程序员试图将“规范专业人士展现专业能力的规则”转化为伪代码，进而编写成软件。[247] 这在法律领域虽取得过一些成果，但专家系统的方法从未得到广泛应用。无论是在交易领域还是诉讼领域，任何真正具备专业知识的从业者，几乎都无法将自己全部的知识与判断力，浓缩成一系列可由机器应用的命题。[248]</p>
     <p> （<span style="color:Green;">根据脚注，这个结论的理由在于那些基于大量经验所形成的理解无法被简化为计算。这对于专家系统来说是正确的，但机器学习正是基于案例来学习，学习经验，这里的理由可能不再适用。取而代之的理由可能是，能够数据化、用于算法学习的案例与真实世界人类感知的经验有差异，存在一些无法数据化的经验/学习材料。例如人生活中的灵感、案件细微的信息等。<br><br>
    【总结】：1、真实世界向数据世界转化的过程中存在信息损耗。2、法官/律师等人类可以从案件之外的现实生活中感知到灵感、道理等，这些想法会影响案件的裁判，但并非都是所谓的偏见、谬误，反而是法律与社会现实对接、回应社会需要、体现人类自治的途径。典型的例子如“《第二十条》中检察官正是因为自己个人生活遭遇不公，才改变了他在工作中唯唯诺诺、向非正义低头的态度。”换句话说，可能不存在一个在不同时代、不同地区、不同社会环境中均正确的裁判结果，裁判结果要反映社会、时代的需要，这种对社会、时代需要的感知，似乎只有生活在其中的人类本身才能感受到。<br><br>
    【对此观点，也有可能的批评】：1、法官阶层可能与普通人脱离，法官是否真的能够感知到普通社会的需要？2、算法一定不能感知社会需要吗？例如通过机器学习持续跟踪社会舆论。但这仍面临真实世界向数据世界转化的信息损耗问题。</span>）即便在远不如当今法律实务复杂的诸多场景中，人类专业技能难以被编码化、标准化的特性，依然普遍存在。[249] 例如，经济学家戴维·奥托尔（David Autor）认为，即便在未来十年左右，即便汽车驾驶能实现完全自动化，汽车挡风玻璃的更换也极不可能实现全自动化。[250]</p>
    <h4>B. 仍保留可清晰表述的标准，在规则与预测的时代</h4>
    <p>普及法律自动化的吸引力，建立在对法治的某种特定理解，以及一种“追求某种效用最大化”的法律义务之上。</p>
    <p>许多批评法院的人士指出，法官往往只是罗列多个需考量的因素，随后便给出某种凭整体印象得出的意见，既未妥善区分对立的法律依据，也未从基本原则出发进行推理以得出判决。[251]（<span style="color:Blue;">这种批评源于法官的裁量空间，认为法官总是给出武断的判断。</span>）法律体系内部对此的明确改革思路，便是尝试制定某种规则，明确判决应依据的标准。例如，在Community for Creative Non-Violence v. Reid——这起版权法中“独立承包商/雇员”区分问题的标志性案件——之后，尽管该案采用了多因素测试法，许多法律评论文章仍试图将“工资税缴纳情况”确立为判断的核心标准。[252][253] 更具雄心的文章可能会尝试用详尽的子规则解释各种情形差异，就像法律论著撰写者倾向于对案件进行类型化梳理一样。[254]</p>
    <p>尽管体系化构建者抱有雄心，但在面对相似事实情形时，不同法院的处理方式几乎总会存在冲突，且这种冲突难以通过逻辑或理性调和。（也就是说，很多情况下不存在一个绝对普适、唯一正确的裁判规则。）</p>
    <p>（<span style="color:Blue;">基于逻辑的推理无法胜任时，转向语义分析的统计方法</span>）对于支持法律预测分析的人而言，当不存在“以理性方式整合各项因素”的明确裁判规则时，自然语言处理方法或许能发挥作用：它可提取过往案件的相关要素（如诉讼文书），建模分析文书中特定表述或结构对裁判者的影响，随后依据未来案件的诉讼文书，推断这些影响在新案件中的作用。（<span style="color:Blue;">机器学习类基于统计概率的计算，而非基于逻辑的推理得出结论。</span>）</p>
    <p>若将这些方法视为“为混乱法律领域建立秩序”的最佳方式，那么律所向客户提供建议的最优路径，便是在其数据库中存储尽可能多的事实情境，将客户案件的事实与所有现有事实进行匹配，进而对法官的裁判结果进行暴力预测。</p>
    <p>这种预测模式，与气象预报员利用大数据（而非底层大气动力学原理）预测风暴移动的方式十分相似。[255] 例如，若对“1000个特定气压的冷锋横扫密歇根州”的数据库进行算法分析，只要参数与算法得当，其对下一个冷锋影响的预测效果，可能会优于未掌握此类数据的专业气象学家。[256] 这类方法也与谷歌（Google）过去十年在翻译领域的技术进展有异曲同工之妙。谷歌翻译（Google Translate）并未采用某种层级化规则体系，将单词、短语或句子从一种语言转换为另一种语言。[257] 相反，它只是即时将待翻译短语与已翻译文档中的相同或相似短语进行匹配，随后在该文档的译文里找到匹配短语，再将其应用于目标语境中。[258] 谷歌的翻译程序并未解析其所译文字的含义，本质上只是对过往人类译文进行索引，并将其与当前待翻译内容匹配。[259] 在处理较复杂的翻译任务时，它或许会推断如何最佳融合不同译文——但它仍需依赖人类反馈来判断译文质量的优劣。[260]</p>
    <p>专家系统与基于预测分析的机器学习方法，绝非法律分析自动化领域中相互冲突的路径，而是推动法律替代性自动化的高度互补手段。（<span style="color:Green;">人类的思维也是这样双重互补的，一定的基础知识/规则+经验积累，但区别在于人类能够“理解”这些知识，机器无法理解。不过以人类的思维来理解也并不一定必要。人类的理解思维可能只是理解、建构世界的方式之一，但因为任何造物都应该服务于人类社会，人类是社会的主体，机器思维或许需要适应人类社会的建构。</span>）</p>
    <p>一旦预测分析者对案件进行“远距解读”[261]——将裁判者（的工作）当成“接收输入（事实模式）并生成输出（判决）、却难以明确输入如何转化为输出”的黑箱，就会产生将系统形式化的压力。[262] 人们有理由要求了解“结果为何会产生”。而法律的形式化程度越高，就越容易将其规则转化为类似“TurboTax（税务申报软件）”这类程序所采用的专家系统。</p>
    <p>【基于rule和standard的讨论来分析算法法律决策】</p>
    <p>因此，在一些极端场景下（规则非常确定和非常不确定的情况），法律自动化软件或许比人类律师更具优势。</p>
    <p>如果某一领域的法律完全不确定，算法分析可能会发现人类难以察觉的案件模式，进而通过暴力预测成功推断出可能的法律结果。[263]</p>
    <p>相反，如果法律体系极为有序，专家系统则可将其简化为一系列可执行的规则。[264]（<span style="color:Blue;">这里认为，在极端确定和极端不确定的情况下，算法可能都比人类有优势，这种论断是否正确？从两种算法的优点出发，进行逻辑推理得到的结论是这样的。</span>）</p>
    <p>对人类律师而言幸运的是，当前多数活跃的法律领域既不属于前者，也不属于后者——且本就不应如此。在规则的绝对清晰与不受约束的自由裁量权所导致的混乱之间，存在着“可清晰表述的标准”：这些标准能帮助我们为法律决策构建有说服力的解释与正当理由，同时又不会提前注定结果。（<span style="color:Blue;">现实的情况大多是介于完全确定和不确定之间，既不是rule也不是混沌无规律，而是标准standard。</span>）</p>
    <p>企业可能会抱怨，在针对它们的申诉或执法行动发起前，法院或机构未能明确阐述适用某部法律的清晰规则。[265]（<span style="color:Blue;">关于rule和standard的讨论。</span>）但这类争议在20世纪40年代就已有了定论。[266] 正如最高法院在SEC v. Chenery Corp.中所裁定的：“通过个案逐步形成法定标准，无疑具有重要意义。”[267][268] 一个人性化的法律体系，需要灵活适应新现实与政治变革，（通过个案形成裁判标准，凸显了标准是跟随社会变化逐步形成的、不是一蹴而就的。同时，要实现这种逐步形成的过程，也需要给裁判者保留一定的空间来发挥。用算法来替代裁判者，是否是立法权对司法权的侵犯和替代？）而这正是其核心要求。</p>
    <p>即便是天气预报——这类启发了大量法律自动化尝试的预测建模典范——也已认可人类判断力具有不可替代的重要性，正如社会学家Phaedra Daipha所指出的：“（美国国家气象局，NWS）的官方表述中充斥着还原论语言（reductionist）与技术官僚术语，预报员们也乐于认同一种天真的实证主义科学观——即便他们对这种观点保持着讽刺性的距离，或者说正因为如此。但另一方面，美国国家气象局的操作指南却明确且反复地将‘数值预测模型如何辅助完成工作’的判断权与裁量权，交由预报员自主决定。”[269]</p>
    <p>即便在气象学领域，判断力也至关重要。更何况，与法官或监管者不同，气象学家无需承担“理解各方利益与主张”的明确职责，也无需担忧“在个案中实现正义”与“为未来案件树立最优先例”之间可能存在的矛盾。由此可见，在法律领域，人类决策者保留裁量权的合理性——进而延伸到，在向这些决策者陈情时所采用的法律实务形式中保留裁量空间的合理性——远胜于气象学领域。（<span style="color:Blue;">相比于一般需要做出判断的专业，法官在做出判断时需要“理解各方利益与主张”、平衡“个案中实现正义”与“为未来案件树立最优先例”之间的矛盾。因此更需要保留人类的裁量空间。这里需要与A right to human decision 那篇文章的观点进行比较。）</p>
    <p>灵活性对于监管快速发展领域的机构而言尤为重要。[270] 这种灵活性必然会“打破”法律人工智能支持者所推崇的暴力预测模型与专家系统模型。</p>
    <p>对司法与行政机关裁量权而言，灵活性是一项优势，而非缺陷。过去许多试图使法律合理化、算法化的努力均以失败告终，且理由充分：无法通过公平的方式，将以往决策群体的思维过程推及所有新场景。（旧的裁判无法完全适应新的情况，需要法官借助裁量空间主动地创造。）</p>
    <p>例如，在社会保障残疾认定中引入“预设因素网格”，本可被轻易解读为这类决策走向自动化的前奏。[271] 但很快，裁量空间便以各种形式融入该网格——为的是对患病与残疾申请人所呈现的、无限多样的事实场景作出公正处理。[272]</p>
    <p>这并非要完全否定人工智能在法律领域的应用。当清晰明确的规则演变为模糊标准（反之亦然）时，暴力预测工具或许能为客户提供咨询帮助。[273] 它们还能在偏见开始显现时向决策者发出警示。[274] 例如，行为经济学领域的一项著名研究近期发现，法官在午餐后批准假释申请的比例高于午餐前。[275] 理想情况下，这类研究不应促使预测分析公司去寻找影响决策的其他无关因素，并为客户提供利用这些因素的建议（比如派身材高大的律师向被发现偏爱高个子律师的法官陈情）。相反，这一令人不安的发现更应被视为一种提醒：法官在意识到这种“饥饿偏见”后，应着手制定防范措施（若无法做到，则应定期加餐）。[276] 其他行业的专业人士，如医生与药剂师，会常规性地将自动化警报用作“防护栏”，以警示可能出现的错误决策。[277] 这类决策支持工具并非用算法取代人类，而是朝着完善“人类决策者与机器辅助决策分析相结合的社会技术系统”又迈进了一步。[278]（<span style="color:Blue;">人机系统，做出更好的决策判断。</span>）</p>
    <h3>结论</h3>
    <p>像法律这样复杂领域的自动化，可能会引发适得其反的后果。人工智能虽被宣传为“简化法律服务”的手段，却极易扭曲或违背其本应支持的目标。标准化法律文书可能会背离其表面上所服务的客户的诉求。软件固然能大幅简化合规流程，但若是通过淡化、轻视或忽视法律条文的重要方面来实现这一点，那便是对法治的背弃——而非将法治转化为代码。</p>
    <p>尽管存在这些问题（其中许多要么尚未解决，要么解决得不够充分），法律未来主义者仍在持续推动法律自动化的加速发展。[279] 当客户、律师协会与立法者讨论“应允许软件在多大程度上替代法律顾问与代理服务”时，他们应牢记本文的几个核心观点。</p>
    <p>无论是“适度版”还是“激进版”的替代性法律自动化，要么陷入停滞，要么未能完全实现其宣称的目标。[280] 法律行业应寻求一种替代范式——即“人机协作”的互补性愿景。这种被称为“智能增强（IA）”的务实路径，在过去半个世纪中为计算机领域带来的进展，远多于通用人工智能的构想。[281] 互补性自动化能让人类律师及其他法律行业从业者，更好地应对法律语言的复杂性与精妙性。</p>
    <p>法律科技领域的从业者应谨慎行事，避免将律师的职业角色与“提供专业知识”混为一谈。法治所包含的是一套社会关系与正当治理体系，而非简单的“行为信息传递与评估”。专业群体内部必然存在一定程度的自我管理，这使其职业身份有别于其他劳动者。律师的主要信义义务面向客户，而非管理者或股东。他们之所以能享有这种自主权，核心原因在于：他们必须处理棘手的价值冲突——这类冲突往往需要深思熟虑的裁量与协商。一个健全且符合伦理的法律行业，会将这种“基于法律语言灵活性与精妙性的裁量权”视为“公正且负责任的社会秩序”的前提，并予以尊重。它确保了治理的核心是“人”，而非“机器”。</p>
    <p>（<b><span style="color:Blue;">本文认为应当积极看待法官的自由裁量权，这是灵活、公正社会秩序的保障。</b>）</p>
  </section>
</body>
</html>
